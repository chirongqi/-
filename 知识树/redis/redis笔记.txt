Redis  基础数据结构
	Redis 有 5 种基础数据结构，分别为：string (字符串)、list (列表)、set (集合)、hash (哈
	希) 和 zset (有序集合)
	String 
	Redis 的字符串是动态字符串，是可以修改的字符串，内部结构实现上类似于 Java 的
	ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配，如图中所示，内部为当前字
	符串实际分配的空间 capacity 一般要高于实际字符串长度 len。当字符串长度小于 1M 时，
	扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是
	字符串最大长度为 512M。
	set name codehole 设置
	get name "codehole" 获取
	expire name 5 # 5s 后过期
	setex name 5 codehole # 5s 后过期，等价于 set+expire
	setnx name codehole # 如果 name 不存在就执行 set 创建  返回1成功 0设置不成功

	计数
	如果 value 值是一个整数，还可以对它进行自增操作。自增是有范围的，它的范围是
	signed long 的最大最小值，超过了这个值，Redis 会报错。
	incr age

	list ( 列表)
	Redis 的列表相当于 Java 语言里面的 LinkedList，注意它是链表而不是数组。这意味着list 的插入和删除操作非常快，
	时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为
	O(n)，这点让人非常意外。当列表弹出了最后一个元素之后，该数据结构自动被删除，内存被回收
	右边进左边出：队列
	rpush books python java golang
	lpop books
	右边进右边出：栈
	rpush books python java golang
	rpop books
	快速列表
	如果再深入一点，你会发现 Redis 底层存储的还不是一个简单的 linkedlist，而是称之为
	快速链表 quicklist 的一个结构。
	首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是 ziplist，也即是
	压缩列表。它将所有的元素紧挨着一起存储，分配的是一块连续的内存。当数据量比较多的
	时候才会改成 quicklist。因为普通的链表需要的附加指针空间太大，会比较浪费空间，而且
	会加重内存的碎片化。比如这个列表里存的只是 int 类型的数据，结构上还需要两个额外的
	指针 prev 和 next 。所以 Redis 将链表和 ziplist 结合起来组成了 quicklist。也就是将多个
	ziplist 使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空
	间冗余。


	hash (字典）
	Redis 的字典相当于 Java 语言里面的 HashMap，它是无序字典。内部实现结构上同
	Java 的 HashMap 也是一致的，同样的数组 + 链表二维结构。第一维 hash 的数组位置碰撞
	时，就会将碰撞的元素使用链表串接起来。
	不同的是，Redis 的字典的值只能是字符串，另外它们 rehash 的方式不一样，因为
	Java 的 HashMap 在字典很大时，rehash 是个耗时的操作，需要一次性全部 rehash。Redis
	为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略。
	渐进式 rehash 会在 rehash 的同时，保留新旧两个 hash 结构，查询时会同时查询两个
	hash 结构，然后在后续的定时任务中以及 hash 的子指令中，循序渐进地将旧 hash 的内容
	一点点迁移到新的 hash 结构中。
	当 hash 移除了最后一个元素之后，该数据结构自动被删除，内存被回收。
	hash 结构也可以用来存储用户信息，不同于字符串一次性需要全部序列化整个对象，
	hash 可以对用户结构中的每个字段单独存储。这样当我们需要获取用户信息时可以进行部分
	获取。而以整个字符串的形式去保存用户信息的话就只能一次性全部读取，这样就会比较浪
	费网络流量。
	hash 也有缺点，hash 结构的存储消耗要高于单个字符串，到底该使用 hash 还是字符
	串，需要根据实际情况再三权衡。
	hset books java "think in java" # 命令行的字符串如果包含空格，要用引号括起来
	hget books java


	set (集合）
	Redis 的集合相当于 Java 语言里面的 HashSet，它内部的键值对是无序的唯一的。它的
	内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值 NULL。
	当集合中最后一个元素移除之后，数据结构自动删除，内存被回收。 set 结构可以用来
	存储活动中奖的用户 ID，因为有去重功能，可以保证同一个用户不会中奖两次。
	sadd books python
	smembers books # 注意顺序，和插入的并不一致，因为 set 是无序的
	spop books # 弹出一个


	zset (有序集合）
	zset 可能是 Redis 提供的最为特色的数据结构，它也是在面试中面试官最爱问的数据结
	构。它类似于 Java 的 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部
	value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权
	重。它的内部实现用的是一种叫着「跳跃列表」的数据结构。
	zset 中最后一个 value 被移除后，数据结构自动删除，内存被回收。 zset 可以用来存
	粉丝列表，value 值是粉丝的用户 ID，score 是关注时间。我们可以对粉丝列表按关注时间
	进行排序。
	zset 还可以用来存储学生的成绩，value 值是学生的 ID，score 是他的考试成绩。我们
	可以对成绩按分数进行排序就可以得到他的名次。
	跳跃列表
	zset 内部的排序功能是通过「跳跃列表」数据结构来实现的，它的结构非常特殊，也比
	较复杂。
	因为 zset 要支持随机的插入和删除，所以它不好使用数组来表示。我们先看一个普通的
	链表结构。



	容器型数据结构的通用规则
	list/set/hash/zset 这四种数据结构是容器型数据结构，它们共享下面两条通用规则：
	1 、create if not exists
	如果容器不存在，那就创建一个，再进行操作。比如 rpush 操作刚开始是没有列表的，
	Redis 就会自动创建一个，然后再 rpush 进去新元素。
	2 、drop if no elements
	如果容器里元素没有了，那么立即删除元素，释放内存。这意味着 lpop 操作到最后一
	个元素，列表就消失了。
	过期时间
	Redis 所有的数据结构都可以设置过期时间，时间到了，Redis 会自动删除相应的对象。
	需要注意的是过期是以对象为单位，比如一个 hash 结构的过期是整个 hash 对象的过期，
	而不是其中的某个子 key。
	还有一个需要特别注意的地方是如果一个字符串已经设置了过期时间，然后你调用了
	set 方法修改了它，它的过期时间会消失。

redis常用应用
	分布式锁
	延时队列
	位图
	在我们平时开发过程中，会有一些 bool 型数据需要存取，比如用户一年的签到记录，
	签了是 1，没签是 0，要记录 365 天。如果使用普通的 key/value，每个用户要记录 365
	个，当用户上亿的时候，需要的存储空间是惊人的。
	为了解决这个问题，Redis 提供了位图数据结构，这样每天的签到记录只占据一个位，
	365 天就是 365 个位，46 个字节 (一个稍长一点的字符串) 就可以完全容纳下，这就大大
	节约了存储空间。
	位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是 byte 数组。我们
	可以使用普通的 get/set 直接获取和设置整个位图的内容，也可以使用位图操作 getbit/setbit
	等将 byte 数组看成「位数组」来处理。
	以老钱的经验，在面试中有 Redis 位图使用经验的同学很少，如果你对 Redis 的位图有
	所了解，它将会是你的面试加分项

	布隆过滤器
	布隆过滤器是什么 ？
	布隆过滤器可以理解为一个不怎么精确的 set 结构，当你使用它的 contains 方法判断某
	个对象是否存在时，它可能会误判。但是布隆过滤器也不是特别不精确，只要参数设置的合
	理，它的精确度可以控制的相对足够精确，只会有小小的误判概率。
	当布隆过滤器说某个值存在时，这个值可能不存在；当它说不存在时，那就肯定不存
	在。打个比方，当它说不认识你时，肯定就不认识；当它说见过你时，可能根本就没见过
	面，不过因为你的脸跟它认识的人中某脸比较相似 (某些熟脸的系数组合)，所以误判以前见
	过你。
	Redis 深度历险：核心原理与应用实践 | 钱文品 著
	第 55 页 共 226 页
	套在上面的使用场景中，布隆过滤器能准确过滤掉那些已经看过的内容，那些没有看过
	的新内容，它也会过滤掉极小一部分 (误判)，但是绝大多数新内容它都能准确识别。这样就
	可以完全保证推荐给用户的内容都是无重复的。


	scan指令
	keys 算法是遍历算法，复杂度是 O(n)，如果实例中有千万级以上的 key，这个指令
	就会导致 Redis 服务卡顿，所有读写 Redis 的其它的指令都会被延后甚至会超时报错，因为
	Redis 是单线程程序，顺序执行所有指令，其它指令必须等到当前的 keys 指令执行完了才
	可以继续
	scan 相比
	keys 具备有以下特点:
	1、复杂度虽然也是 O(n)，但是它是通过游标分步进行的，不会阻塞线程;
	2、提供 limit 参数，可以控制每次返回结果的最大条数，limit 只是一个 hint，返回的
	结果可多可少;
	3、同 keys 一样，它也提供模式匹配功能;
	4、服务器不需要为游标保存状态，游标的唯一状态就是 scan 返回给客户端的游标整数;
	5、返回的结果可能会有重复，需要客户端去重复，这点非常重要;
	6、遍历的过程中如果有数据修改，改动后的数据能不能遍历到是不确定的;
	7、单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零;
	scan 参数提供了三个参数，第一个是 cursor 整数值，第二个是 key 的正则模式，第三
	个是遍历的 limit hint。第一次遍历时，cursor 值为 0，然后将返回结果中第一个整数值作为
	下一次遍历的 cursor。一直遍历到返回的 cursor 值为 0 时结束。
	scan 0 match key99* count 1000

	


redis原理1：线程 IO  模型
	Redis  是个单线程程序！这点必须铭记。
		也许你会怀疑高并发的 Redis 中间件怎么可能是单线程。很抱歉，它就是单线程，你的
		怀疑暴露了你基础知识的不足。莫要瞧不起单线程，除了 Redis 之外，Node.js 也是单线
		程，Nginx 也是单线程，但是它们都是服务器高性能的典范。
	Redis  单线程为什么还能这么快？
		因为它所有的数据都在内存中，所有的运算都是内存级别的运算。正因为 Redis 是单线
		程，所以要小心使用 Redis 指令，对于那些时间复杂度为 O(n) 级别的指令，一定要谨慎使
		用，一不小心就可能会导致 Redis 卡顿。
	Redis  单线程如何处理那么多的并发客户端连接？
		这个问题，有很多中高级程序员都无法回答，因为他们没听过多路复用这个词汇，不知
		道 select 系列的事件轮询 API，没用过非阻塞 IO。
非阻塞 IO

	事件轮询 (非阻塞IO）

	指令队列
		Redis 会将每个客户端套接字都关联一个指令队列。客户端的指令通过队列来排队进行
		顺序处理，先到先服务。
	响应队列
		Redis 同样也会为每个客户端套接字关联一个响应队列。Redis 服务器通过响应队列来将
		指令的返回结果回复给客户端。 如果队列为空，那么意味着连接暂时处于空闲状态，不需要
		去获取写事件，也就是可以将当前的客户端描述符从 write_fds 里面移出来。等到队列有数据
		了，再将描述符放进去。避免 select 系统调用立即返回写事件，结果发现没什么数据可以
		写。出这种情况的线程会飙高 CPU。
	定时任务
		服务器处理要响应 IO 事件外，还要处理其它事情。比如定时任务就是非常重要的一件
		事。如果线程阻塞在 select 系统调用上，定时任务将无法得到准时调度。那 Redis 是如何解
		决这个问题的呢？
		Redis 的定时任务会记录在一个称为最小堆的数据结构中。这个堆中，最快要执行的任
		务排在堆的最上方。在每个循环周期，Redis 都会将最小堆里面已经到点的任务立即进行处
		理。处理完毕后，将最快要执行的任务还需要的时间记录下来，这个时间就是 select 系统调
		用的 timeout 参数。因为 Redis 知道未来 timeout 时间内，没有其它定时任务需要处理，所以
		可以安心睡眠 timeout 的时间。
		Nginx 和 Node 的事件处理原理和 Redis 也是类似的.


redis原理2：通信协议
	Redis 的作者认为数据库系统的瓶颈一般不在于网络流量，而是数据库自身内部逻辑处
	理上。所以即使 Redis 使用了浪费流量的文本协议，依然可以取得极高的访问性能。Redis
	将所有数据都放在内存，用一个单线程对外提供服务，单个节点在跑满一个 CPU 核心的情
	况下可以达到了 10w/s 的超高 QPS。
	RESP(Redis Serialization Protocol)
	RESP 是 Redis 序列化协议的简写。它是一种直观的文本协议，优势在于实现异常简
	单，解析性能极好。
	Redis 协议将传输的结构数据分为 5 种最小单元类型，单元结束时统一加上回车换行符
	号\r\n。
	1、单行字符串 以 + 符号开头。
	2、多行字符串 以 $ 符号开头，后跟字符串长度。
	3、整数值 以 : 符号开头，后跟整数的字符串形式。
	4、错误消息 以 - 符号开头。
	5、数组 以 * 号开头，后跟数组的长度。

redis原理3：持久化
	Redis 的数据全部在内存里，如果突然宕机，数据就会全部丢失，因此必须有一种机制
	来保证 Redis 的数据不会因为故障而丢失，这种机制就是 Redis 的持久化机制。
	Redis 的持久化机制有两种，第一种是快照，第二种是 AOF 日志。快照是一次全量备
	份，AOF 日志是连续的增量备份。快照是内存数据的二进制序列化形式，在存储上非常紧
	Redis 深度历险：核心原理与应用实践 | 钱文品 著
	第 101 页 共 226 页
	凑，而 AOF 日志记录的是内存数据修改的指令记录文本。AOF 日志在长期的运行过程中会
	变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长。
	所以需要定期进行 AOF 重写，给 AOF 日志进行瘦身。

快照原理
	我们知道 Redis 是单线程程序，这个线程要同时负责多个客户端套接字的并发读写操作
	和内存数据结构的逻辑读写。
	在服务线上请求的同时，Redis 还需要进行内存快照，内存快照要求 Redis 必须进行文
	件 IO 操作，可文件 IO 操作是不能使用多路复用 API。
	这意味着单线程同时在服务线上的请求还要进行文件 IO 操作，文件 IO 操作会严重拖
	垮服务器请求的性能。还有个重要的问题是为了不阻塞线上的业务，就需要边持久化边响应
	客户端请求。持久化的同时，内存数据结构还在改变，比如一个大型的 hash 字典正在持久
	化，结果一个请求过来把它给删掉了，还没持久化完呢，这尼玛要怎么搞？
	那该怎么办呢？
	Redis 使用操作系统的多进程 COW(Copy On Write) 机制来实现快照持久化，这个机制
	很有意思，也很少人知道。多进程 COW 也是鉴定程序员知识广度的一个重要指标。
	fork( 多进程)
	Redis 在持久化时会调用 glibc 的函数 fork 产生一个子进程，快照持久化完全交给子进
	程来处理，父进程继续处理客户端请求。子进程刚刚产生时，它和父进程共享内存里面的代
	码段和数据段。这时你可以将父子进程想像成一个连体婴儿，共享身体。这是 Linux 操作系
	Redis 深度历险：核心原理与应用实践 | 钱文品 著
	第 102 页 共 226 页
	统的机制，为了节约内存资源，所以尽可能让它们共享起来。在进程分离的一瞬间，内存的
	增长几乎没有明显变化。
	用 Python 语言描述进程分离的逻辑如下。fork 函数会在父子进程同时返回，在父进程
	里返回子进程的 pid，在子进程里返回零。如果操作系统内存资源不足，pid 就会是负数，表
	示 fork 失败。
	pid = os.fork()
	if pid > 0:
	handle_client_requests() # 父进程继续处理客户端请求
	if pid == 0:
	handle_snapshot_write() # 子进程处理快照写磁盘
	if pid < 0:
	# fork error
	子进程做数据持久化，它不会修改现有的内存数据结构，它只是对数据结构进行遍历读
	取，然后序列化写到磁盘中。但是父进程不一样，它必须持续服务客户端请求，然后对内存
	数据结构进行不间断的修改。
	这个时候就会使用操作系统的 COW 机制来进行数据段页面的分离。数据段是由很多操
	作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复
	制一份分离出来，然后对这个复制的页面进行修改。这时子进程相应的页面是没有变化的，
	还是进程产生时那一瞬间的数据。
	Redis 深度历险：核心原理与应用实践 | 钱文品 著
	第 103 页 共 226 页
	随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，内存就会持续增
	长。但是也不会超过原有数据内存的 2 倍大小。另外一个 Redis 实例里冷数据占的比例往
	往是比较高的，所以很少会出现所有的页面都会被分离，被分离的往往只有其中一部分页
	面。每个页面的大小只有 4K，一个 Redis 实例里面一般都会有成千上万的页面。
	子进程因为数据没有变化，它能看到的内存里的数据在进程产生的一瞬间就凝固了，再
	也不会改变，这也是为什么 Redis 的持久化叫「快照」的原因。接下来子进程就可以非常安
	心的遍历数据了进行序列化写磁盘了


redis 过期策略
	过期的 key  集合
	redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定时遍历这个
	字典来删除到期的 key。除了定时遍历之外，它还会使用惰性策略来删除过期的 key，所谓
	惰性策略就是在客户端访问这个 key 的时候，redis 对 key 的过期时间进行检查，如果过期
	了就立即删除。定时删除是集中处理，惰性删除是零散处理.
	
	定时扫描策略
	Redis 默认会每秒进行十次过期扫描，过期扫描不会遍历过期字典中所有的 key，而是
	采用了一种简单的贪心策略。
	1、从过期字典中随机 20 个 key；
	2、删除这 20 个 key 中已经过期的 key；
	3、如果过期的 key 比率超过 1/4，那就重复步骤 1；
	Redis 深度历险：核心原理与应用实践 | 钱文品 著
	第 169 页 共 226 页
	同时，为了保证过期扫描不会出现循环过度，导致线程卡死现象，算法还增加了扫描时
	间的上限，默认不会超过 25ms。



